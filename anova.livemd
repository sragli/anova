# ANOVA

```elixir
Mix.install([
  {:statistics, "~> 0.6"},
  {:kino, "~> 0.7"},
  {:kino_vega_lite, "~> 0.1.10"}
])
```

## Description

ANOVA, or Analysis of Variance is a widely used statistical technique for comparing means among multiple groups, providing insights into whether observed differences are due to actual effects or simply random variability. It's an extension of the t-test, allowing for comparisons among multiple groups simultaneously. One-Way ANOVA compares means of three or more independent groups for one factor.

<!-- livebook:{"break_markdown":true} -->

### Null hypothesis

<!-- livebook:{"break_markdown":true} -->

The null hypothesis of the ANOVA is that all group means are equal (i.e., not significantly different between classes), whereas the alternative hypothesis is that at least one mean is different from the others.

<!-- livebook:{"break_markdown":true} -->

### Assumptions

<!-- livebook:{"break_markdown":true} -->

* Homogeneity of variances: Assumes that the variance within each group is equal, but is fairly robust to violations of homogeneity of variances, especially when sample sizes are similar across groups and the departures from homogeneity are not extreme.
* Independence of observations: Assumes that observations within each group are independent.
* Normally distributed data: Assumes that the data within each group are normally distributed.

## Input

### Test data

```elixir
groups = [
  [1, 2, 1, 0],
  [2, 3, 2, 1],
  [7, 7, 10, 8],
  [5, 4, 5, 6]
]
```

### Significance level

<!-- livebook:{"break_markdown":true} -->

Measure of the strength (probability) of the evidence that must be present in the sample before rejecting the null hypothesis:

```elixir
significance_level = 0.05
```

## Algorithm

```elixir
group_means =
  for g <- groups do
    Enum.sum(g) / length(g)
  end
```

```elixir
overall_mean = Enum.sum(group_means) / length(group_means)
```

#### Sum of Squares

<!-- livebook:{"break_markdown":true} -->

The total variance explained by between-group differences (SSR) and within-group variability (SSE).

<!-- livebook:{"break_markdown":true} -->

##### Sum of Squares Regression (SSR)

<!-- livebook:{"break_markdown":true} -->

The SSR is computed by taking the square of the difference between the mean group and the overall mean, multiplied by the number of observations in the group, and then taking the sum of all cells:

```elixir
ssr =
  for i <- 0..(length(groups) - 1) do
    length(Enum.at(groups, i)) * :math.pow(Enum.at(group_means, i) - overall_mean, 2)
  end
  |> Enum.sum()
```

##### Sum of Squares Error (SSE)

<!-- livebook:{"break_markdown":true} -->

The SSE is computed by taking the square of the difference between each observation and its group mean, and then taking the sum of all cells:

```elixir
sse =
  for i <- 0..(length(groups) - 1) do
    for v <- Enum.at(groups, i) do
      :math.pow(v - Enum.at(group_means, i), 2)
    end
  end
  |> List.flatten()
  |> Enum.sum()
```

#### Degrees of Freedom (Df)

<!-- livebook:{"break_markdown":true} -->

Represents the number of independent pieces of information available for calculating variances. It is computed as follows:

* for the line regression: number of groups - 1
* for the line error: number of observations - number of groups

```elixir
df_r = length(groups) - 1
```

```elixir
df_e = length(List.flatten(groups)) - length(groups)
```

#### Mean Square

<!-- livebook:{"break_markdown":true} -->

Variance estimates obtained by dividing the sum of squares by their respective degrees of freedom (MS<sub>R</sub> and MS<sub>E</sub>)
It is equal to the sum of square divided by the degrees of freedom:

```elixir
ms_r = ssr / df_r
```

```elixir
ms_e = sse / df_e
```

#### F-value

<!-- livebook:{"break_markdown":true} -->

The F ratio is a statistical measure used to assess the ratio of variance between groups to the variance within groups. It helps determine whether the means of multiple groups are significantly different from each other.
The F Ratio is calculated as the ratio of the between-group variance to the within-group variance:

```elixir
f_value = ms_r / ms_e
```

If there is no significant difference between the group means (null hypothesis is true), the F ratio is expected to be close to 1.
A high F ratio indicates that the between-group variance is significantly larger than the within-group variance, suggesting that the means of at least some groups are likely different from each other.
To determine whether the observed F ratio is significant, it is compared to a critical value from the F-distribution table, considering the degrees of freedom for both numerator and denominator (between groups and within groups, respectively) and the chosen significance level (alpha).
If the F-value is greater than the F-critical value, then the results of the test are statistically significant.

<!-- livebook:{"break_markdown":true} -->

#### F-critical value

```elixir
f_crit = Statistics.Distributions.F.ppf(df_r, df_e).(1 - significance_level)
```

#### P-value

<!-- livebook:{"break_markdown":true} -->

Significance, indicates the probability of obtaining the observed F ratio if the null hypothesis (no group differences) were true. A low p-value (<0.05) suggests strong evidence against the null hypothesis.

```elixir
p_value = 1 - Statistics.Distributions.F.cdf(df_r, df_e).(f_value)
```

#### Effect size

<!-- livebook:{"break_markdown":true} -->

While statistical significance (p-value) indicates whether observed differences are likely due to chance, effect sizes complement this by quantifying the magnitude or practical importance of these differences. Larger effect sizes suggest stronger relationships between variables, regardless of statistical significance.

Guidelines for Interpreting Effect Sizes:

* Small Effect: Around 0.01 (1% of variance explained) can be considered a small effect size. It suggests that the independent variable explains a relatively small portion of the variability in the dependent variable.
* Medium Effect: Approximately 0.06 to 0.14 (6% to 14% of variance explained) could be deemed a medium effect size. It implies a moderate degree of influence of the independent variable on the dependent variable.
* Large Effect: Effect sizes of 0.14 or higher (>14% of variance explained) can be seen as a large effect size. It indicates a substantial impact of the independent variable on the variation observed in the dependent variable.

```elixir
effect_size = ssr / (ssr + sse)
```

### Results

```elixir
data = [
  %{
    "" => "Between groups",
    "SS" => ssr,
    "df" => df_r,
    "MS" => ms_r,
    "F-value" => f_value,
    "P-value" => p_value,
    "F-crit" => f_crit,
    "Effect Size" => effect_size
  },
  %{
    "" => "Within groups",
    "SS" => sse,
    "df" => df_e,
    "MS" => ms_e,
    "F-value" => "",
    "P-value" => "",
    "F-crit" => "",
    "Effect Size" => ""
  },
  %{
    "" => "Total",
    "SS" => ssr + sse,
    "df" => df_r + df_e,
    "MS" => "",
    "F-value" => "",
    "P-value" => "",
    "F-crit" => "",
    "Effect Size" => ""
  }
]

Kino.DataTable.new(
  data,
  keys: ["", "SS", "df", "MS", "F-value", "P-value", "F-crit", "Effect Size"]
)
```

```elixir
if f_value > f_crit do
  "H0 rejected"
end
```
